{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sqlite3 reference: https://docs.python.org/3.6/library/sqlite3.html\n",
    "- sqlite cli reference: https://sqlite.org/cli.html (useful to explore DBs and tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database connection:\n",
    "- ':memory:' creates a temporary database in the computer memory (RAM, faster access)\n",
    "- path: creates/open a database on the filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get connection cursor -> used to execute sql queries\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE People (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  firstname TEXT,\n",
    "  lastname TEXT\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7efe7132db20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit() #commit() needed to apply all the pending operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * from People')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "personA = ('mario', 'rossi')\n",
    "\n",
    "# insertion in a table, argument can be a tuple\n",
    "cur.execute('INSERT INTO People (firstname, lastname) VALUES (?,?)', personA)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'mario', 'rossi')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * from People')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [('paolo', 'neri'), ('jhon', 'doe')]\n",
    "\n",
    "#inserting multiple values at once with executemany() and list of tuples\n",
    "cur.executemany('INSERT INTO People (firstname, lastname) VALUES (?, ?)', people)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded values (or string concatenation) -> not a best practice\n",
    "cur.execute('INSERT INTO People (firstname, lastname) VALUES (\"luca\", \"neri\")')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'paolo', 'neri')\n",
      "(4, 'luca', 'neri')\n"
     ]
    }
   ],
   "source": [
    "# a SELECT query returns a list of rows (as tuples)\n",
    "lastname = 'neri'\n",
    "for row in cur.execute(f'SELECT * from People WHERE lastname=\"{lastname}\"'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting a row\n",
    "cur.execute('DELETE FROM People WHERE firstname=\"luca\" AND lastname=\"neri\"')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'mario', 'rossi'), (2, 'paolo', 'neri'), (3, 'jhon', 'doe')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * from People')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('INSERT INTO People (firstname, lastname) VALUES (\"luca\", \"neri\")')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'mario', 'rossi')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query results are stored inside the cursos object.\n",
    "# we can use fetchone[fetchall] to get one first row[list of rows]\n",
    "# see fetchone(), fetchall(), fetchmany(n)\n",
    "cur.execute('SELECT * from People')\n",
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 'paolo', 'neri')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple fetchone() calls -> get the next result\n",
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no such table: Animals\n",
      "<class 'sqlite3.OperationalError'>\n"
     ]
    }
   ],
   "source": [
    "# trying to insert data into a non-existing table -> exception raised\n",
    "try:\n",
    "    cur.execute('INSERT INTO Animals (firstname, lastname) VALUES (\"cane\", \"cane\")')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(type(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close connection to database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON dataset to SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  tweet.zip\r\n",
      "   creating: SampleFromData/\r\n",
      "  inflating: SampleFromData/1000002204978372608  \r\n",
      "  inflating: SampleFromData/1000001566110339074  \r\n",
      "  inflating: SampleFromData/1000001778904166401  \r\n",
      "  inflating: SampleFromData/1000001970009182208  \r\n",
      "  inflating: SampleFromData/1000001726852759552  \r\n",
      "  inflating: SampleFromData/1000001524339224577  \r\n",
      "  inflating: SampleFromData/1000001821858062336  \r\n",
      "  inflating: SampleFromData/1000002148376236032  \r\n",
      "  inflating: SampleFromData/1000001661606203392  \r\n",
      "  inflating: SampleFromData/1000001570703069188  \r\n",
      "  inflating: SampleFromData/1000001759379705858  \r\n",
      "  inflating: SampleFromData/1000001560297005056  \r\n",
      "  inflating: SampleFromData/1000002204089102336  \r\n",
      "  inflating: SampleFromData/1000002015702016000  \r\n",
      "  inflating: SampleFromData/1000001530232299520  \r\n",
      "  inflating: SampleFromData/1000001911100182528  \r\n",
      "  inflating: SampleFromData/1000002164020957184  \r\n",
      "  inflating: SampleFromData/1000002121889087491  \r\n",
      "  inflating: SampleFromData/1000002030675611648  \r\n",
      "  inflating: SampleFromData/1000001681441075200  \r\n",
      "  inflating: SampleFromData/1000002112447811584  \r\n",
      "  inflating: SampleFromData/1000002147155574787  \r\n",
      "  inflating: SampleFromData/1000000016637972481  \r\n",
      "  inflating: SampleFromData/1000002032940474368  \r\n",
      "  inflating: SampleFromData/1000000682848673792  \r\n",
      "  inflating: SampleFromData/1000000464845524992  \r\n",
      "  inflating: SampleFromData/1000000644491763712  \r\n",
      "  inflating: SampleFromData/1000000322620788736  \r\n",
      "  inflating: SampleFromData/1000002135000526850  \r\n",
      "  inflating: SampleFromData/1000001520690257923  \r\n",
      "  inflating: SampleFromData/1000000039442411521  \r\n",
      "  inflating: SampleFromData/1000000791694934016  \r\n",
      "  inflating: SampleFromData/1000000294128898048  \r\n",
      "  inflating: SampleFromData/1000000967683821569  \r\n",
      "  inflating: SampleFromData/1000000230287462400  \r\n",
      "  inflating: SampleFromData/1000001498460377090  \r\n",
      "  inflating: SampleFromData/1000000274205958144  \r\n",
      "  inflating: SampleFromData/1000000720995848193  \r\n",
      "  inflating: SampleFromData/1000001360803266561  \r\n",
      "  inflating: SampleFromData/1000001069731151872  \r\n",
      "  inflating: SampleFromData/1000001110109753344  \r\n",
      "  inflating: SampleFromData/1000000372457558020  \r\n",
      "  inflating: SampleFromData/1000001012118315008  \r\n",
      "  inflating: SampleFromData/1000000820556034048  \r\n",
      "  inflating: SampleFromData/1000002206098223104  \r\n",
      "  inflating: SampleFromData/1000002278349312007  \r\n",
      "  inflating: SampleFromData/1000000384981786630  \r\n",
      "  inflating: SampleFromData/1000000322562088962  \r\n",
      "  inflating: SampleFromData/1000000303620472834  \r\n",
      "  inflating: SampleFromData/1000001306554056704  \r\n",
      "  inflating: SampleFromData/1000000822779043840  \r\n",
      "  inflating: SampleFromData/1000000817577984001  \r\n",
      "  inflating: SampleFromData/1000002459316707328  \r\n",
      "  inflating: SampleFromData/1000000840214745088  \r\n",
      "  inflating: SampleFromData/1000002248796246016  \r\n",
      "  inflating: SampleFromData/1000000119922724864  \r\n",
      "  inflating: SampleFromData/1000001457448513536  \r\n",
      "  inflating: SampleFromData/1000001205190496256  \r\n",
      "  inflating: SampleFromData/1000000196657459200  \r\n",
      "  inflating: SampleFromData/1000000297304055809  \r\n",
      "  inflating: SampleFromData/1000001083509559296  \r\n",
      "  inflating: SampleFromData/1000001284580302848  \r\n",
      "  inflating: SampleFromData/1000000138293719040  \r\n",
      "  inflating: SampleFromData/1000001007772946432  \r\n",
      "  inflating: SampleFromData/1000001503212593153  \r\n",
      "  inflating: SampleFromData/1000000083797118976  \r\n",
      "  inflating: SampleFromData/1000000714297544704  \r\n",
      "  inflating: SampleFromData/1000000308335046656  \r\n",
      "  inflating: SampleFromData/1000000734954512384  \r\n",
      "  inflating: SampleFromData/1000000288579833857  \r\n",
      "  inflating: SampleFromData/1000001158822481921  \r\n",
      "  inflating: SampleFromData/1000000669632385024  \r\n",
      "  inflating: SampleFromData/1000001276242006017  \r\n",
      "  inflating: SampleFromData/1000000057771548673  \r\n",
      "  inflating: SampleFromData/1000002355843264514  \r\n",
      "  inflating: SampleFromData/1000000218128113665  \r\n",
      "  inflating: SampleFromData/1000000175467909122  \r\n",
      "  inflating: SampleFromData/1000001065897615360  \r\n",
      "  inflating: SampleFromData/1000000610039627783  \r\n",
      "  inflating: SampleFromData/1000001075099906048  \r\n",
      "  inflating: SampleFromData/1000001602592309248  \r\n",
      "  inflating: SampleFromData/1000001089926828033  \r\n",
      "  inflating: SampleFromData/1000000566821638144  \r\n",
      "  inflating: SampleFromData/1000000907667496960  \r\n",
      "  inflating: SampleFromData/1000000217348018177  \r\n",
      "  inflating: SampleFromData/1000000769888841729  \r\n",
      "  inflating: SampleFromData/1000002470456758272  \r\n",
      "  inflating: SampleFromData/1000000751379283969  \r\n",
      "  inflating: SampleFromData/1000001423256453120  \r\n",
      "  inflating: SampleFromData/1000000772459941888  \r\n",
      "  inflating: SampleFromData/1000001416969138176  \r\n",
      "  inflating: SampleFromData/1000000152726327298  \r\n",
      "  inflating: SampleFromData/1000001453040259073  \r\n",
      "  inflating: SampleFromData/1000001501069303808  \r\n",
      "  inflating: SampleFromData/1000001337990483968  \r\n",
      "  inflating: SampleFromData/1000000764151033857  \r\n",
      "  inflating: SampleFromData/1000002348557709312  \r\n",
      "  inflating: SampleFromData/1000000511247114240  \r\n",
      "  inflating: SampleFromData/1000001118070550528  \r\n",
      "  inflating: SampleFromData/1000000684467544064  \r\n",
      "  inflating: SampleFromData/1000001211880411136  \r\n",
      "  inflating: SampleFromData/1000001729642094593  \r\n",
      "  inflating: SampleFromData/1000001150291148800  \r\n",
      "  inflating: SampleFromData/1000000711273402370  \r\n",
      "  inflating: SampleFromData/1000002263136522240  \r\n",
      "  inflating: SampleFromData/1000001016631316483  \r\n",
      "  inflating: SampleFromData/1000000497930076162  \r\n",
      "  inflating: SampleFromData/1000000263871193088  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip tweet.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"usernameTweet\": \"CervoVolante\", \"ID\": \"1000002204978372608\", \"text\": \"Gli state dando i compiti per gli esami ?????\", \"url\": \"/CervoVolante/status/1000002204978372608\", \"nbr_retweet\": 0, \"nbr_favorite\": 0, \"nbr_reply\": 0, \"datetime\": \"2018-05-25 09:14:39\", \"is_reply\": true, \"is_retweet\": false, \"user_id\": \"190688480\"}"
     ]
    }
   ],
   "source": [
    "!head SampleFromData/1000002204978372608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new file database to store the tweets\n",
    "conn = sqlite3.connect('tweet.sqlite3')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table structure inferred from json files\n",
    "query = \"\"\"\n",
    "CREATE TABLE Tweets (\n",
    "    usernameTweet TEXT,\n",
    "    ID TEXT PRIMARY KEY UNIQUE,\n",
    "    text TEXT,\n",
    "    url TEXT,\n",
    "    nbr_retweet INTEGER,\n",
    "    nbr_favorite INTEGER,\n",
    "    nbr_reply INTEGER,\n",
    "    datetime TEXT,\n",
    "    is_reply BOOLEAN,\n",
    "    is_retweet BOOLEAN,\n",
    "    user_id TEXT\n",
    ")\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we forgot a column, we can add it to the table with the ALTER statement\n",
    "cur.execute('ALTER TABLE Tweets ADD has_media BOOLEAN')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media tables, to store the (optional) media URIs which can be found in a tweet\n",
    "query = \"\"\"\n",
    "CREATE TABLE Medias(\n",
    "    media_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    tweet_id TEXT,\n",
    "    media_uri TEXT,\n",
    "    FOREIGN KEY(tweet_id) REFERENCES Tweets(ID)\n",
    ")\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all of the json files\n",
    "for filename in glob.glob('SampleFromData/*'):\n",
    "    data = read_json(filename)\n",
    "    medias = []\n",
    "    \n",
    "    # if the tweet has medias:\n",
    "    # - add all media entries to the list (medias)\n",
    "    # - delete medias object from the json data (we can infer this by joining Tweets\n",
    "    #                                            and Medias table)\n",
    "    if 'medias' in data:\n",
    "        for media in data['medias']:\n",
    "            medias.append((data['ID'], media))\n",
    "        \n",
    "        del data['medias']\n",
    "        \n",
    "    keys = data.keys()\n",
    "    \n",
    "    placeholders = ('?,'*len(keys))[:-1]\n",
    "    keys = ', '.join(keys)\n",
    "    values = data.values()\n",
    "    \n",
    "    try:\n",
    "        cur.execute('INSERT INTO Tweets ({0}) VALUES ({1})'.format(keys, placeholders), list(values))\n",
    "        if len(medias) > 0:\n",
    "            cur.executemany('INSERT INTO Medias (tweet_id, media_uri) VALUES (?, ?)', medias)\n",
    "    \n",
    "    # prevent unique index constraint fail (ID column) if we run this cell\n",
    "    # more than once\n",
    "    except sqlite3.IntegrityError as r: \n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(data)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize pending inserts (from cell above)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GiuliaCrivelli',\n",
       " '1000001083509559296',\n",
       " 'grazie Presidente!!!!!',\n",
       " '/GiuliaCrivelli/status/1000001083509559296',\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " '2018-05-25 09:10:12',\n",
       " 1,\n",
       " 0,\n",
       " '586429781',\n",
       " None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM Tweets LIMIT 10')\n",
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '1000000751379283969', 'https://t.co/2NIWx9bUma'),\n",
       " (2, '1000000610039627783', 'https://t.co/YgE3tDs1LM'),\n",
       " (3, '1000001089926828033', 'https://t.co/IkJe1WVsEp'),\n",
       " (4, '1000001211880411136', 'https://t.co/aaXzPBs6Yx'),\n",
       " (5, '1000001118070550528', 'https://t.co/vf71oZtovx'),\n",
       " (6, '1000000791694934016', 'https://t.co/CV77QNnYMx'),\n",
       " (7, '1000001205190496256', 'https://t.co/hGXBHlcsAt'),\n",
       " (8, '1000001726852759552', 'https://t.co/lIAiqCmXfc'),\n",
       " (9, '1000000566821638144', 'https://t.co/AbPxCrtVck')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM Medias')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
