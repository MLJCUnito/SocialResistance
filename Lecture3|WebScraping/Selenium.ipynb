{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage of Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.python.org\")\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"pycon\")\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A python script as app (client-side) to control a web-app IPTV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from subprocess import run,DEVNULL\n",
    "\n",
    "PASS = '8cstu894jtoesidfosiegjosjfsdg'\n",
    "\n",
    "def getVideo(chn):\n",
    "    XPATH = \"//tr[td[text()='\" + chn + \".\" + \"']]/td/a\"\n",
    "    channel = drv.find_element_by_xpath(XPATH)\n",
    "    URL = channel.get_attribute('href')\n",
    "    return run(\"mpv \"+ URL + \" &\", shell=True,stderr=DEVNULL,stdout=DEVNULL)\n",
    "\n",
    "\n",
    "drv = webdriver.Chrome()\n",
    "drv.get('https://sx2.mooo.com:45210/slag1')\n",
    "\n",
    "advBtn = wait(drv, 10).until(EC.element_to_be_clickable((By.ID, 'details-button')))\n",
    "advBtn.click()\n",
    "proLink = wait(drv, 10).until(EC.element_to_be_clickable((By.ID, 'proceed-link')))\n",
    "proLink.click()\n",
    "\n",
    "textBox = wait(drv, 10).until(EC.element_to_be_clickable((By.XPATH, \"//input[@type='text']\")))\n",
    "textBox.send_keys(PASS)\n",
    "textBox.send_keys(Keys.RETURN);\n",
    "\n",
    "while True:\n",
    "    chan = input('Channel: ')\n",
    "    getVideo(chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium and BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "#launch url\n",
    "url = \"http://kanview.ks.gov/PayRates/PayRates_Agency.aspx\"\n",
    "\n",
    "# create a new Firefox session\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "\n",
    "#After opening the url above, Selenium clicks the specific agency link\n",
    "python_button = driver.find_element_by_id('MainContent_uxLevel1_Agencies_uxAgencyBtn_33') #FHSU\n",
    "python_button.click() #click fhsu link\n",
    "\n",
    "#Selenium hands the page source to Beautiful Soup\n",
    "soup_level1=BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "datalist = [] #empty list\n",
    "x = 0 #counter\n",
    "\n",
    "#Beautiful Soup finds all Job Title links on the agency page and the loop begins\n",
    "for link in soup_level1.find_all('a', id=re.compile(\"^MainContent_uxLevel2_JobTitles_uxJobTitleBtn_\")):\n",
    "    \n",
    "    #Selenium visits each Job Title page\n",
    "    python_button = driver.find_element_by_id('MainContent_uxLevel2_JobTitles_uxJobTitleBtn_' + str(x))\n",
    "    python_button.click() #click link\n",
    "    \n",
    "    #Selenium hands of the source of the specific job page to Beautiful Soup\n",
    "    soup_level2=BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "    #Beautiful Soup grabs the HTML table on the page\n",
    "    table = soup_level2.find_all('table')[0]\n",
    "    \n",
    "    #Giving the HTML table to pandas to put in a dataframe object\n",
    "    df = pd.read_html(str(table),header=0)\n",
    "    \n",
    "    #Store the dataframe in a list\n",
    "    datalist.append(df[0])\n",
    "    \n",
    "    #Ask Selenium to click the back button\n",
    "    driver.execute_script(\"window.history.go(-1)\") \n",
    "    \n",
    "    #increment the counter variable before starting the loop over\n",
    "    x += 1\n",
    "    \n",
    "    #end loop block\n",
    "    \n",
    "#loop has completed\n",
    "\n",
    "#end the Selenium browser session\n",
    "driver.quit()\n",
    "\n",
    "#combine all pandas dataframes in the list into one big dataframe\n",
    "result = pd.concat([pd.DataFrame(datalist[i]) for i in range(len(datalist))],ignore_index=True)\n",
    "\n",
    "#convert the pandas dataframe to JSON\n",
    "json_records = result.to_json(orient='records')\n",
    "\n",
    "#pretty print to CLI with tabulate\n",
    "#converts to an ascii table\n",
    "print(tabulate(result, headers=[\"Employee Name\",\"Job Title\",\"Overtime Pay\",\"Total Gross Pay\"],tablefmt='psql'))\n",
    "\n",
    "#get current working directory\n",
    "path = os.getcwd()\n",
    "\n",
    "#open, write, and close the file\n",
    "f = open(path + \"\\\\fhsu_payroll_data.json\",\"w\") #FHSU\n",
    "f.write(json_records)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
